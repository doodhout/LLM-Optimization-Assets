# Effective Workflows for LLM-Assisted Development

## Overview

The most successful LLM-assisted development follows structured workflows rather than ad-hoc prompting. This guide presents battle-tested workflows that maximize productivity while maintaining code quality.

## Core Workflow Principle

**The fundamental truth about LLM-assisted development:**

> **Small, iterative changes with verification beats large, monolithic implementations every time.**

**Why:**
- Large implementations become unwieldy quickly
- Harder to review and understand
- Debugging is nightmare
- Context window fills up
- Quality degrades
- Lost productivity when things go wrong

**Evidence:**
Studies and user reports consistently show that developers who break tasks into small, verified iterations are 3-5x more productive than those who try to implement large features in one go.

**Community consensus from r/ClaudeAI:**
> "I learned the hard way: Never let Claude write more than 200 lines without testing. Break everything into small, testable chunks." - Top-voted workflow advice

## The Core Workflow Pattern

### The Plan-Implement-Test-Review Cycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    PLAN     â”‚  Small, focused task
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ IMPLEMENT   â”‚  Write minimal code
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    TEST     â”‚  Verify it works
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   REVIEW    â”‚  Check quality
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   COMMIT    â”‚  Save progress
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â””â”€â”€â”€â”€â”€â”€> Next task (repeat cycle)
```

**Each cycle should take: 15-45 minutes**

**Why this works:**
- Constant verification prevents drift
- Small chunks are manageable
- Easy to debug problems
- Git history is meaningful
- Can rollback easily
- Momentum through small wins
- Context stays focused

### Cycle Size Guidelines

**Good cycle sizes:**
- âœ… Single function implementation
- âœ… One component with tests
- âœ… Single bug fix
- âœ… One API endpoint
- âœ… Small refactoring of single module

**Too large (split into smaller cycles):**
- âŒ Entire feature with multiple files
- âŒ Major refactoring across codebase
- âŒ Multiple related features
- âŒ "Implement the dashboard"
- âŒ Anything taking >1 hour

**Too small (can be combined):**
- âš ï¸ Single line change (unless bug fix)
- âš ï¸ Trivial formatting
- âš ï¸ Adding one import

## âœ… DO: Effective Workflow Patterns

### 1. **Start Every Task with Planning**

**Pattern: Planning Session**

```
â”Œâ”€ Planning Session (10-15 minutes) â”€â”
â”‚                                     â”‚
â”‚ 1. Understand the requirement      â”‚
â”‚ 2. Break into subtasks             â”‚
â”‚ 3. Identify dependencies           â”‚
â”‚ 4. Plan order of implementation    â”‚
â”‚ 5. Identify risks/unknowns         â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Example:**

âŒ **Bad approach:**
```
Human: "Implement user authentication"
Claude: [Generates 800 lines of code across 10 files]
```

âœ… **Good approach:**
```
Human: "Help me plan implementing user authentication"

Claude: Let's break this down:

1. Core authentication (Session 1)
   - Password hashing utils
   - Login/logout logic
   - Tests

2. Middleware (Session 2)
   - Auth middleware
   - Route protection
   - Tests

3. Endpoints (Session 3)
   - POST /auth/login
   - POST /auth/logout
   - GET /auth/me
   - Tests

4. Integration (Session 4)
   - Connect to existing routes
   - Error handling
   - Integration tests

Let's start with #1...
```

**Benefits:**
- Clear roadmap
- Manageable chunks
- Can pause/resume easily
- Stakeholders can review plan
- Risks identified early

### 2. **Implement One Component at a Time**

**Pattern: Single-Responsibility Implementation**

**Rules:**
- Work on exactly one file/module/component per cycle
- Implement its tests immediately
- Verify before moving on
- Commit before next component

**Example workflow:**

```
Cycle 1: AuthService
â”œâ”€ Implement: src/services/AuthService.ts
â”œâ”€ Test: src/services/AuthService.test.ts
â”œâ”€ Run tests: npm test AuthService
â””â”€ Commit: "feat: implement AuthService"

Cycle 2: AuthMiddleware
â”œâ”€ Implement: src/middleware/auth.ts
â”œâ”€ Test: src/middleware/auth.test.ts
â”œâ”€ Run tests: npm test auth.middleware
â””â”€ Commit: "feat: implement auth middleware"

Cycle 3: Auth Routes
â”œâ”€ Implement: src/routes/auth.ts
â”œâ”€ Test: src/routes/auth.test.ts
â”œâ”€ Run tests: npm test auth.routes
â””â”€ Commit: "feat: implement auth routes"

Cycle 4: Integration
â”œâ”€ Connect components
â”œâ”€ Integration tests
â”œâ”€ Run all tests: npm test
â””â”€ Commit: "feat: integrate auth system"
```

**Why it works:**
- Each piece is simple enough to understand
- Tests verify each piece works
- Debugging is straightforward
- Can stop and resume easily
- Git history tells a story

**User testimonial:** "I stopped trying to implement entire features at once. Now it's one file, tests, commit. Repeat. 10x more productive."

### 3. **Test After Every Change**

**Pattern: Continuous Verification**

**Never accumulate untested code.**

**Workflow:**
```
1. Write code
   â†“
2. Write/update tests
   â†“
3. Run tests
   â†“
4. Tests pass?
   â”œâ”€ YES â†’ Proceed to review
   â””â”€ NO â†’ Fix immediately
```

**Why immediate testing matters:**

**Scenario: Test after each change**
```
Change 1 â†’ Test (pass) â†’
Change 2 â†’ Test (pass) â†’
Change 3 â†’ Test (fail) â†’ Fix Change 3 immediately

Result: Know exactly what broke, fix in 2 minutes
```

**Scenario: Test after all changes**
```
Change 1 â†’
Change 2 â†’
Change 3 â†’
All done â†’ Test (fail) â†’ Now what broke???

Result: Debug 3 changes, fix in 30 minutes
```

**Evidence:**
15x faster debugging when testing continuously vs testing at the end.

### 4. **Review Before Committing**

**Pattern: Quality Gate**

**Review checklist:**
```markdown
Before committing, verify:
- [ ] Code works (tests pass)
- [ ] Code is clean and readable
- [ ] No debug code left (console.log, etc.)
- [ ] Error handling is appropriate
- [ ] Edge cases are handled
- [ ] Documentation/comments if needed
- [ ] Follows project conventions
- [ ] No obvious security issues
- [ ] Performance is acceptable
```

**Techniques:**

**Technique 1 - Self-review:**
```
Human: "Review the changes we just made. Check for:
- Bugs or edge cases
- Code quality issues
- Better approaches
- Potential problems"
```

**Technique 2 - Fresh eyes:**
Start new conversation, ask Claude to review the changes without context of creating them.

**Technique 3 - Specialized agent:**
Use a code review agent (see agent best practices guide).

**Why it works:**
- Catches issues before they become technical debt
- Maintains code quality
- Learning opportunity
- Prevents accumulating problems

### 5. **Commit Frequently with Clear Messages**

**Pattern: Meaningful Git History**

**Frequency: After each cycle (every 15-45 minutes)**

**Commit message format:**
```
<type>: <short description>

<optional longer description>
<optional notes about decisions made>

Example:
feat: implement JWT authentication service

- Added token generation and validation
- Includes refresh token support
- Token expiry set to 1 hour

Decided to use jsonwebtoken library over jose for broader compatibility
```

**Why frequent commits matter:**
- Easy rollback if something goes wrong
- Clear history of development
- Can pause and resume easily
- Safe to experiment (can always revert)
- Documents decision-making process

**User insight:** "Small, frequent commits saved my ass so many times. Break something? Revert. Lost? Check recent commits to remember what you were thinking."

### 6. **Use Branch-Per-Task for Larger Work**

**Pattern: Isolated Development**

**Workflow:**
```
main branch
    â”‚
    â”œâ”€> feature/user-auth (new branch)
    â”‚   â”œâ”€ Cycle 1: AuthService
    â”‚   â”œâ”€ Cycle 2: AuthMiddleware
    â”‚   â”œâ”€ Cycle 3: Auth Routes
    â”‚   â””â”€ Cycle 4: Integration
    â”‚
    â””â”€> (merge when feature complete)
```

**Benefits:**
- Main branch stays stable
- Can abandon work if needed
- Easy to share work-in-progress
- Clear scope for feature
- Enables code review before merge

**Antipattern:** Working directly on main branch for multi-day features.

### 7. **Take Breaks Between Cycles**

**Pattern: Sustainable Pace**

**Why breaks matter:**
- LLM-assisted development is cognitively intense
- Review quality degrades when tired
- Fresh perspective after break
- Prevents rubber-stamping Claude's suggestions

**Recommended rhythm:**
```
Cycle 1 (30 min)
  â†’ Break (5 min)
Cycle 2 (30 min)
  â†’ Break (5 min)
Cycle 3 (30 min)
  â†’ Longer break (15 min)
Cycle 4 (30 min)
  â†’ Break (5 min)
...
```

**After 4-5 cycles: Take 30+ minute break**

**Evidence:**
Developer productivity research shows that breaks improve both speed and quality. Tired developers make more mistakes and miss issues in review.

## âŒ DON'T: Workflow Anti-Patterns

### 1. **Don't Let Claude Write Hundreds of Lines Without Testing**

**The problem:**

```
âŒ Bad:
Human: "Implement the entire user management system"
Claude: [Generates 1500 lines across 12 files]
Human: "Let's test it"
Result: 37 errors, 2 hours to debug, maybe easier to restart
```

**Why it fails:**
- Bugs compound across files
- Hard to know what's wrong where
- Context window full of broken code
- Lost time on debugging
- Often faster to restart than fix

**The 200-line rule:**
> "Never let Claude write more than 200 lines without running and testing the code."
> - r/ClaudeAI consensus

**Better:**
```
âœ… Good:
Human: "Implement UserService with basic CRUD (one file)"
Claude: [Generates ~150 lines]
Human: [Tests it]
Result: Works! Moving on to next component.
```

### 2. **Don't Skip the Planning Phase**

**The problem:**
```
âŒ Bad:
Human: "Build a dashboard"
Claude: "Let me start coding..."
[2 hours later]
Human: "This isn't what I wanted..."
```

**Why it fails:**
- No shared understanding
- Wasted effort on wrong approach
- Have to start over
- Frustrating for everyone

**Better:**
```
âœ… Good:
Human: "Help me plan a dashboard feature"
Claude: "What data should it show? Who's the user? What actions?"
[10 minute planning discussion]
Claude: "Here's my implementation plan: ..."
Human: "Looks good, let's implement phase 1"
[Efficient implementation]
```

**Time investment:**
- Planning: 10-15 minutes
- Time saved: Hours of rework

### 3. **Don't Accumulate Technical Debt**

**The problem:**
```
âŒ Bad pattern:
Cycle 1: "I'll fix that later"
Cycle 2: "Another small issue, I'll batch them"
Cycle 3: "Okay, lots of TODOs now..."
Cycle 4: "This is getting unwieldy..."
Result: Technical debt crisis
```

**Why it fails:**
- TODOs never get done
- Debt compounds
- Future work builds on shaky foundation
- Eventually have to stop and refactor

**Better:**
```
âœ… Good pattern:
Cycle 1: Notice issue â†’ Fix immediately (2 minutes)
Cycle 2: Notice issue â†’ Fix immediately (3 minutes)
Cycle 3: Notice issue â†’ Fix immediately (2 minutes)
Result: Clean code, no debt
```

**The rule: Fix it now if it takes <5 minutes**

### 4. **Don't Trust Without Verifying**

**The problem:**
```
âŒ Bad:
Claude: "Here's the implementation"
Human: "Looks good!" [Commits without testing]
[Later] "Wait, this doesn't work..."
```

**Why it fails:**
- LLMs make mistakes
- Subtle bugs slip through
- Assumptions may be wrong
- Edge cases missed

**Better:**
```
âœ… Good:
Claude: "Here's the implementation"
Human: [Reads code, runs tests, tries edge cases]
Human: "Found an issue with null handling"
Claude: [Fixes it]
Human: [Tests again, verifies]
Human: "Now it's good!" [Commits]
```

**Trust but verify: Always test before committing**

### 5. **Don't Work in One Mega-Conversation**

**The problem:**
```
âŒ Bad:
Day 1: Start conversation, implement feature A
Day 2: Same conversation, implement feature B
Day 3: Same conversation, implement feature C
Day 4: Same conversation, now it's confused...

Context: 150K tokens of mixed history
Result: Claude mixing up features, hallucinating earlier decisions
```

**Why it fails:**
- Context window fills with irrelevant history
- Model confuses different features
- Performance degrades
- Can't find relevant information

**Better:**
```
âœ… Good:
Day 1: Conversation 1 â†’ Feature A â†’ Summary document
Day 2: Conversation 2 â†’ Feature B â†’ Summary document
Day 3: Conversation 3 â†’ Feature C â†’ Summary document
Day 4: Fresh context, reference summaries as needed

Each conversation: Focused, clear context
Result: Consistent, high-quality output
```

**The conversation size limit:**
> Start fresh after 50 exchanges or 3-4 hours of work

### 6. **Don't Skip Code Review**

**The problem:**
```
âŒ Bad:
Claude generates code â†’ Commit immediately
Claude generates code â†’ Commit immediately
[Repeat 10x]
Result: Low-quality code, bugs, inconsistencies
```

**Why it fails:**
- LLMs make mistakes
- May not follow all conventions
- Subtle bugs creep in
- Code quality degrades

**Better:**
```
âœ… Good:
Claude generates code â†’ Human reviews â†’ Fix issues â†’ Test â†’ Commit
Claude generates code â†’ Human reviews â†’ Fix issues â†’ Test â†’ Commit

Optional: Periodic comprehensive review with fresh Claude conversation
```

**Code review should take: 20-30% of implementation time**

## Advanced: Dev Docs System for Complex Tasks

### The Problem: Claude Loses Track

**Common scenario:**
```
Hour 1: Start implementing feature, everything on track
Hour 2: Making good progress, handling edge cases
Hour 3: Wait, what were we implementing again?
Result: Realized Claude went on a tangent and lost the original plan
```

**Why it happens:**
- Claude is like an "extremely confident junior dev with extreme amnesia"
- Long conversations accumulate context
- Original plan gets buried or forgotten
- Auto-compaction wipes context
- Easy to drift from original intent

### The Solution: Persistent Dev Docs

**Create a documentation trail for every large task:**

```bash
dev/
â””â”€â”€ active/
    â””â”€â”€ [task-name]/
        â”œâ”€â”€ [task-name]-plan.md        # The accepted plan
        â”œâ”€â”€ [task-name]-context.md     # Key files, decisions, integrations
        â””â”€â”€ [task-name]-tasks.md       # Checklist of work items
```

### Starting Large Tasks

**Workflow:**

**1. Enter Planning Mode**
Even if you'll write the plan to markdown later, planning mode helps Claude:
- Gather context more efficiently
- Analyze project structure thoroughly
- Create comprehensive plans
- Research the codebase effectively

**2. Review the Plan Thoroughly**
- Take time to understand every part
- Catch misunderstandings early
- Verify Claude understood the requirements
- Identify missing pieces

**3. Create Dev Docs Structure**
```bash
mkdir -p ~/git/project/dev/active/[task-name]/
```

**4. Generate Three Core Documents**

Using a custom slash command or directly with Claude:

**`[task-name]-plan.md`:**
```markdown
# Feature: User Authentication System

## Executive Summary
Implement JWT-based authentication with refresh tokens

## Phases
### Phase 1: Core Auth Service
- Password hashing utilities
- Token generation and validation
- Refresh token support

### Phase 2: Middleware & Protection
- Auth middleware
- Route protection
- Permission checking

### Phase 3: API Endpoints
- POST /auth/login
- POST /auth/logout
- POST /auth/refresh
- GET /auth/me

### Phase 4: Integration
- Connect to existing routes
- Error handling
- Integration tests

## Risks & Mitigations
- Risk: Token expiry edge cases
  Mitigation: Comprehensive test coverage

## Success Metrics
- All tests passing
- Auth flow works end-to-end
- Performance within 200ms

## Timeline
Estimated: 3-4 days (with testing)
```

**`[task-name]-context.md`:**
```markdown
# Context: User Authentication

## Key Files
- src/services/AuthService.ts - Core auth logic
- src/middleware/auth.ts - Route protection
- src/routes/auth.ts - Auth endpoints
- src/models/User.ts - User model

## Integration Points
- Existing user management system
- Database: PostgreSQL via Prisma
- Email service for verification

## Key Decisions
- Decision: Use JWT over sessions
  Reason: Better for distributed systems
  Made: 2024-01-15

- Decision: 1-hour token expiry
  Reason: Security vs UX balance
  Made: 2024-01-15

## Dependencies
- jsonwebtoken library
- bcrypt for password hashing

**Last Updated:** 2024-01-15 14:30
```

**`[task-name]-tasks.md`:**
```markdown
# Tasks: User Authentication

## Phase 1: Core Auth Service
- [ ] Implement password hashing utility
- [ ] Implement token generation
- [ ] Implement token validation
- [ ] Add refresh token support
- [ ] Write unit tests

## Phase 2: Middleware
- [ ] Create auth middleware
- [ ] Add route protection
- [ ] Write middleware tests

## Phase 3: Endpoints
- [ ] POST /auth/login
- [ ] POST /auth/logout
- [ ] POST /auth/refresh
- [ ] GET /auth/me
- [ ] Write endpoint tests

## Phase 4: Integration
- [ ] Connect to existing routes
- [ ] Error handling
- [ ] Integration tests
- [ ] Documentation

**Last Updated:** 2024-01-15 14:30
```

**5. Implement with Constant Reference**

Throughout implementation:
- Reference dev docs frequently
- Update tasks as completed (immediately!)
- Add new context/decisions as they emerge
- Track next steps before running low on context

### Continuing After Context Loss

**When starting a fresh conversation:**

```
Human: "Continue working on user authentication.
Read these files:
- dev/active/user-auth/user-auth-plan.md
- dev/active/user-auth/user-auth-context.md
- dev/active/user-auth/user-auth-tasks.md

Pick up where we left off."

Claude: [Reads files, understands full context, continues seamlessly]
```

### Updating Dev Docs Before Compaction

**When context is running low:**

Create a slash command like `/update-dev-docs`:

```markdown
# .claude/commands/update-dev-docs.md
Review the current task and update the dev docs:

1. Mark completed tasks in [task-name]-tasks.md
2. Add any new tasks discovered during implementation
3. Update [task-name]-context.md with:
   - New decisions made
   - New integration points discovered
   - Next steps for resuming work
4. Update "Last Updated" timestamps

Be specific about next steps so work can resume smoothly.
```

**Result:** Clean handoff to next conversation, no lost context.

### Benefits of Dev Docs System

**Before dev docs:**
- Claude loses track during long tasks
- Have to restart when context is lost
- Difficult to resume after breaks
- Tangents derail the original plan
- Auto-compaction wipes critical context

**After dev docs:**
- Clear plan always available
- Easy resume after breaks or compaction
- Tangents get caught (compare to plan)
- All decisions documented
- Smooth handoffs between conversations

**Community insight:**
> "The dev docs system, out of everything besides skills, has made the most impact on results. Claude is like an extremely confident junior dev with extreme amnesia - this system addresses that perfectly." - 6-month production user

### Critical Importance: Context Window Limits are the Hidden Bottleneck

**The reality most developers discover too late:**

Context window limits are not just a technical constraintâ€”they are **the single most disruptive factor** in LLM-assisted development workflows. Studies show developers lose 30-60 minutes per session when context resets without proper management systems.

**Why this matters more than you think:**

```
Without proper context management:
- Every context reset = complete information loss
- Implementation decisions forgotten
- Key file purposes rediscovered each time
- Task progress reset to zero
- Technical constraints re-explained repeatedly
- Hours wasted on "catching Claude back up"
```

**The Context Rot Problem:**

Research has uncovered "context rot": as tokens in the context window increase, the model's ability to accurately recall information **decreases**. This characteristic emerges across all models, making context a finite resource with diminishing marginal returns.

Even Claude 3.7 Sonnet's 200,000 token context window faces the "lost-in-the-middle effect"â€”where LLMs weigh the beginning and end of prompts more heavily due to primacy and recency bias, causing important middle context to be undervalued.

**Real-world impact:**

> "Context loss between sessions creates significant workflow disruptions for complex development projects, forcing developers to repeatedly re-explain everything when opening new windows or tabs." - GitHub Issue #2954, Claude Code

> "Developers are implementing sophisticated external memory systems, multi-agent architectures, and complex session logging just to maintain basic project continuity." - Context Sync Product Hunt Discussion

### Deep Dive: The Dev Docs Pattern in Detail

The dev docs pattern from [claude-code-infrastructure-showcase](https://github.com/diet103/claude-code-infrastructure-showcase) provides the most comprehensive solution to context persistence we've found. Here's why it works:

#### The Three-File Architecture

**Critical Design Principle:** Each file serves a distinct purpose in the context preservation lifecycle.

**File Location:** `dev/active/[task-name]/`

**1. [task-name]-plan.md - The Strategic Blueprint**

**Purpose:** High-level strategy that rarely changes

**Critical Contents:**
```markdown
# Executive Summary
One-paragraph overview of what we're building and why

# Current State Analysis
- What exists now
- What's broken/missing
- Why current approach isn't sufficient

# Future State Vision
- What we want to achieve
- How it solves the problem
- Success looks like...

# Implementation Phases
## Phase 1: [Name]
**Objective:** Clear goal
**Tasks:**
- Specific, actionable task 1
- Specific, actionable task 2
**Acceptance Criteria:**
- Measurable success indicator
**Dependencies:** What must be complete first

## Phase 2: [Name]
[Repeat structure]

# Risk Assessment
- **Risk:** Specific concern
- **Likelihood:** High/Medium/Low
- **Impact:** High/Medium/Low
- **Mitigation:** Concrete approach

# Success Metrics
- How we measure completion
- Performance benchmarks
- Quality gates

# Timeline Estimates
Phase 1: X days
Phase 2: Y days
Total: Z days
```

**When to update:** Only when scope changes significantly or new phases emerge

**Why it works:** Provides stable, high-level direction that Claude can reference without requiring updates

---

**2. [task-name]-context.md - The Living State Document**

**Purpose:** Current working state and decision log

**Critical Structure:**
```markdown
# SESSION PROGRESS (âš ï¸ UPDATE THIS FREQUENTLY)

## Last Updated: [Timestamp]

## Completed Work
- âœ… Implemented UserAuthService.ts with JWT generation
- âœ… Created auth middleware with token validation
- âœ… Added error handling for expired tokens

## Currently Working On
ğŸ”„ Implementing refresh token endpoint
- File: src/routes/auth.ts
- Current status: 60% complete
- Next step: Add refresh token validation logic

## Immediate Next Steps
1. Complete refresh token validation
2. Add integration tests for refresh flow
3. Update auth documentation

## Blockers / Issues
- âš ï¸ Need clarification on token rotation policy
- ğŸ”´ TypeScript error in AuthMiddleware.ts line 45 (priority)

---

# Key Files and Their Purposes

## Core Authentication Files
- **src/services/AuthService.ts**: JWT generation, validation, refresh
  - Why important: Central auth logic, used by all protected routes
  - Key functions: generateToken(), validateToken(), refreshToken()

- **src/middleware/auth.ts**: Request authentication
  - Why important: Guards all protected API endpoints
  - Integration: Applied to routes in src/routes/index.ts

- **src/routes/auth.ts**: Auth endpoints
  - Why important: Public API for authentication
  - Endpoints: /login, /logout, /refresh, /me

## Related Configuration
- **src/config/jwt.ts**: JWT configuration
- **src/types/auth.ts**: Auth TypeScript types

---

# Important Architectural Decisions

## Decision: JWT vs Sessions (2024-01-15)
**Chosen:** JWT tokens
**Reasoning:**
- Better for distributed systems
- No server-side session storage needed
- Easier horizontal scaling
**Trade-offs:**
- Can't revoke tokens before expiry
- Slightly larger request size

## Decision: 1-hour token expiry (2024-01-15)
**Chosen:** 1 hour access token, 7 day refresh token
**Reasoning:**
- Security: Limits exposure if token stolen
- UX: Refresh tokens prevent constant re-login
**Implementation:** Set in src/config/jwt.ts

## Decision: httpOnly cookies vs localStorage (2024-01-16)
**Chosen:** httpOnly cookies for refresh tokens
**Reasoning:**
- XSS protection: JavaScript can't access
- CSRF protection via SameSite attribute
**Trade-offs:**
- More complex for mobile apps
- Requires CORS configuration

---

# Technical Constraints Discovered

- Database: PostgreSQL via Prisma ORM
  - Must use repository pattern for consistency
  - All queries must go through UserRepository

- Error Handling: All errors must use Sentry
  - Pattern: try-catch with Sentry.captureException()
  - Location: Established in src/utils/errorHandler.ts

- Testing: Jest + Supertest required
  - All endpoints need integration tests
  - Minimum 80% coverage for auth code

---

# Quick Resume Instructions

**To continue this work:**
1. Read this context file completely
2. Review current progress in SESSION PROGRESS section
3. Check tasks.md for what's marked complete
4. Start with "Immediate Next Steps"
5. Update this file after each major milestone
```

**Update Frequency:** CRITICALâ€”after every major milestone, completion, or discovery

**Why it works:**
- SESSION PROGRESS provides instant orientation
- Decisions are documented with reasoning (prevents rework)
- Constraints are explicit (prevents violations)
- Resume instructions eliminate guesswork

---

**3. [task-name]-tasks.md - The Action Checklist**

**Purpose:** Granular, actionable task tracking

**Critical Format:**
```markdown
# Tasks: User Authentication System

## Status Legend
- âœ… Complete
- ğŸŸ¡ In Progress
- â³ Blocked
- â¬œ Not Started

---

## Phase 1: Core Auth Service

### Password Hashing
- âœ… Install bcrypt dependency
- âœ… Implement hashPassword() utility
- âœ… Implement comparePassword() utility
- âœ… Add unit tests for hashing functions

**Acceptance Criteria:**
- Passwords hashed with bcrypt rounds=10
- Comparison function returns boolean correctly
- Tests cover valid/invalid passwords
- Error handling for malformed input

---

### JWT Token Generation
- âœ… Install jsonwebtoken dependency
- âœ… Create JWT configuration in src/config/jwt.ts
- ğŸŸ¡ Implement generateToken() in AuthService.ts
- â¬œ Add token expiry logic
- â¬œ Unit tests for token generation

**Acceptance Criteria:**
- Tokens signed with HS256 algorithm
- Payload includes userId, email, roles
- Expiry set to 1 hour
- Secret loaded from environment variable
- Tests verify payload structure

**Current Status (generateToken):**
- Basic implementation complete
- Need to add: refresh token generation
- Next: Implement token expiry in 30 minutes

---

### Token Validation
- â¬œ Implement validateToken() in AuthService.ts
- â¬œ Add error handling for expired tokens
- â¬œ Add error handling for invalid signatures
- â¬œ Unit tests for validation

**Acceptance Criteria:**
- Validates signature correctly
- Detects expired tokens
- Returns decoded payload or null
- Logs validation failures
- Tests cover all error cases

**Dependencies:**
- Requires: generateToken() complete

---

## Phase 2: Middleware & Protection

### Auth Middleware
- â¬œ Create src/middleware/auth.ts
- â¬œ Implement authenticateRequest() middleware
- â¬œ Extract token from Authorization header
- â¬œ Validate token and attach user to request
- â¬œ Handle missing/invalid token cases
- â¬œ Integration tests with mock routes

**Acceptance Criteria:**
- Middleware extracts Bearer token from header
- Adds req.user object on success
- Returns 401 for missing token
- Returns 403 for invalid token
- Tests verify all paths

---

## Phase 3: API Endpoints

### POST /auth/login
- â¬œ Create route handler in src/routes/auth.ts
- â¬œ Validate email/password from request
- â¬œ Query user from database
- â¬œ Compare password hash
- â¬œ Generate tokens on success
- â¬œ Return tokens in response
- â¬œ Integration tests

**Acceptance Criteria:**
- Accepts JSON: {email, password}
- Returns 200 with {accessToken, refreshToken}
- Returns 401 for invalid credentials
- Returns 400 for missing fields
- Logs failed login attempts
- Tests cover success + error cases

---

### GET /auth/me
- â¬œ Create protected route handler
- â¬œ Apply auth middleware
- â¬œ Return current user data
- â¬œ Integration tests

**Acceptance Criteria:**
- Requires valid access token
- Returns user object: {id, email, roles}
- Returns 401 if not authenticated
- Tests verify token requirement

---

## Phase 4: Integration & Polish

### Integration Testing
- â¬œ End-to-end auth flow test
- â¬œ Token refresh flow test
- â¬œ Protected route access test
- â¬œ Error scenario tests

### Documentation
- â¬œ API documentation for auth endpoints
- â¬œ Update README with auth setup
- â¬œ Add JSDoc comments to AuthService

### Performance
- â¬œ Benchmark token generation speed
- â¬œ Verify database query performance
- â¬œ Check middleware overhead

---

# Notes

## Discovered During Implementation
- 2024-01-16: Refresh tokens need separate table for revocation support
- 2024-01-16: Consider rate limiting on /auth/login endpoint

## Future Enhancements (Post-MVP)
- Two-factor authentication
- OAuth integration (Google, GitHub)
- Password reset flow
- Email verification
```

**Update Frequency:** Mark tasks complete IMMEDIATELY as you finish them

**Why it works:**
- Checkbox format is visually scannable
- Acceptance criteria make "done" unambiguous
- Status indicators show progress at a glance
- Notes capture discoveries without cluttering the plan
- Dependencies prevent working out of order

### Pro Tips

**1. Limit Scope Per Cycle**
```
Instead of:
"Implement the entire plan"

Do this:
"Implement only Phase 1, sections 1-2. We'll do Phase 1 section 3 next."
```

**Benefit:** Get to review code between each set of tasks, catch issues early.

**2. Have Claude Review Its Own Code**
Between phases, launch a code review agent:
- Catches critical errors early
- Identifies missing implementations
- Finds inconsistent code
- Spots security flaws

**3. Update Context During Implementation**
Don't wait until end to document:
```
Human: "We just decided to use httpOnly cookies for refresh tokens.
Add this decision to the context file."
```

**4. Create Slash Commands**
Make the workflow repeatable:
- `/dev-docs` - Create initial dev docs from plan
- `/update-dev-docs` - Update before compaction
- `/review-progress` - Review tasks and next steps

**5. When to Use Dev Docs vs When to Skip**

**Use dev docs for:**
- âœ… Tasks expected to take >2 hours
- âœ… Work spanning multiple sessions
- âœ… Complex features with many moving parts
- âœ… Large system refactoring
- âœ… Multi-day projects
- âœ… Anything that will hit context limits

**Skip dev docs for:**
- âŒ Simple bug fixes (< 30 minutes)
- âŒ Single-file changes
- âŒ Quick updates or tweaks
- âŒ Exploratory work without clear scope

**The 2-hour rule:** If a task might exceed 2 hours or span sessions, create dev docs. Time invested upfront saves hours later.

## Comprehensive Comparison: Context Window Management Approaches

### Overview of Available Strategies

Based on extensive research and real-world usage patterns, here are all major approaches to managing context window limits in LLM-assisted development:

| Approach | Type | Complexity | Effectiveness | Cost |
|----------|------|------------|---------------|------|
| Dev Docs Pattern | File-based | Medium | â­â­â­â­â­ | Free |
| CLAUDE.md/Static Files | File-based | Low | â­â­â­ | Free |
| Built-in Session Commands | Native | Low | â­â­ | Free |
| MCP External Memory | Tool-based | High | â­â­â­â­ | Free-Paid |
| Vector DB/RAG | Infrastructure | Very High | â­â­â­â­ | Paid |
| Sub-agent Architecture | Architectural | High | â­â­â­â­ | Free |
| Chunking/Summarization | Technique | Low-Medium | â­â­ | Free |

---

### 1. Dev Docs Pattern (Three-File Structure)

**What it is:** Version-controlled markdown files (plan.md, context.md, tasks.md) stored in `dev/active/[task-name]/`

**Strengths:**
- â­â­â­â­â­ **Persistence:** Survives all context resets indefinitely
- â­â­â­â­â­ **Completeness:** Captures strategy, state, and tasks separately
- â­â­â­â­â­ **Version control:** Git-trackable, shareable with team
- â­â­â­â­â­ **Zero infrastructure:** Just markdown files
- â­â­â­â­â­ **Human readable:** You can read and edit manually
- â­â­â­â­ **Resume speed:** 30 seconds to full context restoration
- â­â­â­â­ **Scalability:** Works for 1-week or 6-month projects

**Weaknesses:**
- âš ï¸ Requires discipline to update context.md frequently
- âš ï¸ Manual process (though can be slash-command automated)
- âš ï¸ Doesn't auto-update (relies on human/Claude to maintain)
- âš ï¸ Can become stale if not updated during implementation

**Best for:**
- Complex multi-day/multi-week features
- Team projects requiring handoffs
- Production work with high stakes
- Projects with evolving requirements

**Real-world effectiveness:**
> "Read 3 files and resume instantly with full context; hours saved per reset" - claude-code-infrastructure-showcase

**Evidence:** Proven in 300k LOC production rewrite over 6 months

**Ranking: ğŸ¥‡ #1 Overall for Complex Tasks**

---

### 2. CLAUDE.md / Implementation Strategy Files

**What it is:** Static markdown files at project root containing rules, patterns, and architectural decisions

**Strengths:**
- â­â­â­â­ **Simple:** Single file, easy to set up
- â­â­â­â­ **Persistent:** Survives all sessions
- â­â­â­â­ **Shareable:** Team members benefit equally
- â­â­â­â­ **Low maintenance:** Set and mostly forget
- â­â­â­ **Auto-loaded:** Claude reads on session start

**Weaknesses:**
- âš ï¸ Staticâ€”doesn't capture current task state
- âš ï¸ Becomes bloated if trying to do too much
- âš ï¸ No task progress tracking
- âš ï¸ Doesn't help with "where was I?" after context reset
- âš ï¸ Can't track session-specific decisions

**Best for:**
- Project-level conventions and patterns
- Architectural guidelines
- Coding standards
- Tool configurations
- Things that NEVER change mid-task

**How it compares to Dev Docs:**
- **Different purpose:** CLAUDE.md = "how to write code in this project" while Dev Docs = "what are we currently building and where are we"
- **Complementary:** Use BOTH together for best results
- **CLAUDE.md covers:** Patterns, conventions, architecture
- **Dev Docs covers:** Current task, progress, decisions specific to current work

**Evidence:**
> "Implementation strategy documents save thousands of tokens in subsequent sessionsâ€”instead of re-analyzing the entire codebase, the agent simply reads its own strategy document." - Context Engineering Research

**Ranking: ğŸ¥ˆ #2 for Project-Level Context, Not a Replacement for Dev Docs**

---

### 3. Built-in Session Commands (/compact, /clear, /resume)

**What it is:** Native Claude Code commands for managing conversation state

**Available commands:**
- `/compact` - Summarize conversation and start fresh with summary
- `/clear` - Wipe context completely
- `/resume [session-id]` - Continue previous conversation
- `--continue` - Resume most recent conversation

**Strengths:**
- â­â­â­â­â­ **Native:** Built into Claude Code
- â­â­â­â­â­ **Zero setup:** Works immediately
- â­â­â­â­ **Fast:** Instant execution
- â­â­â­ **Summarization:** /compact creates condensed context

**Weaknesses:**
- âš ï¸âš ï¸ **Lossy:** Summarization loses nuance and details
- âš ï¸âš ï¸ **Ephemeral:** Resume only works for recent sessions
- âš ï¸âš ï¸ **No long-term persistence:** Can't resume from weeks ago
- âš ï¸âš ï¸ **Limited control:** Can't choose what to keep
- âš ï¸ **Fragile:** Summaries may miss critical details

**Best for:**
- Quick context cleanup during active sessions
- Reducing token usage when context is filling up
- Resuming very recent work (same day)

**How it compares to Dev Docs:**
- **Timeframe:** Session commands = hours, Dev Docs = weeks/months
- **Reliability:** Session commands = lossy, Dev Docs = lossless
- **Control:** Session commands = automatic, Dev Docs = explicit
- **Use together:** /compact when context fills + Dev Docs for persistence

**Evidence:**
> "/clear should be used as often as possible, ideally whenever you finish a task, to reduce unnecessary token usage" - Claude Code Session Management Guide

**Ranking: ğŸ¥‰ #3 for Short-Term Context Management, Not Suitable for Complex Projects**

---

### 4. MCP-Based External Memory Systems

**What it is:** Model Context Protocol servers that provide persistent memory across sessions

**Examples:**
- **Context Sync:** Syncs conversations, decisions, and project state across tools
- **Task Orchestrator:** Persistent external memory with sub-agent architecture
- **Custom MCP servers:** Project-specific memory implementations

**Strengths:**
- â­â­â­â­â­ **Automatic:** Memory persists without manual updates
- â­â­â­â­â­ **Cross-tool:** Works across Claude Desktop, Cursor, etc.
- â­â­â­â­ **Queryable:** AI can search past context
- â­â­â­â­ **Scalable:** Handles massive context accumulation
- â­â­â­â­ **Token efficient:** Up to 90% token reduction (Task Orchestrator)

**Weaknesses:**
- âš ï¸âš ï¸ **Setup complexity:** Requires MCP server installation
- âš ï¸âš ï¸ **Infrastructure:** External dependency
- âš ï¸âš ï¸ **Potential cost:** Some solutions are paid
- âš ï¸ **Black box:** Less transparent than markdown files
- âš ï¸ **Vendor lock-in:** Tied to specific MCP implementation

**Best for:**
- Teams needing cross-tool context sharing
- Projects with dozens of concurrent tasks
- Organizations with dedicated DevOps resources
- Workflows requiring automatic context capture

**How it compares to Dev Docs:**
- **Automation:** MCP = automatic, Dev Docs = semi-manual
- **Transparency:** MCP = opaque, Dev Docs = human-readable
- **Reliability:** MCP = depends on server, Dev Docs = just files
- **Setup:** MCP = complex, Dev Docs = create 3 files
- **Cost:** MCP = can be paid, Dev Docs = free

**Evidence:**
> "Task Orchestrator implements patterns recommended in Anthropic's context engineering research: sub-agent architectures, compaction through summarization, just-in-time context loading, and persistent external memory. Scaling to 50+ tasks with up to 90% token reduction" - Task Orchestrator GitHub

**Ranking: ğŸ–ï¸ #4 for Large Teams/Organizations, Overkill for Solo Developers**

---

### 5. Vector Database / RAG (Retrieval-Augmented Generation)

**What it is:** Store embeddings of code snippets and project data in vector DB, query to retrieve relevant info

**Technical approach:**
- Chunk codebase into segments
- Generate embeddings for each chunk
- Store in vector database (Pinecone, Weaviate, etc.)
- Query at session start to retrieve relevant context

**Strengths:**
- â­â­â­â­â­ **Semantic search:** Finds conceptually relevant code
- â­â­â­â­ **Massive scale:** Handles million+ line codebases
- â­â­â­â­ **Automatic:** No manual documentation needed
- â­â­â­â­ **Just-in-time:** Loads only relevant context

**Weaknesses:**
- âš ï¸âš ï¸âš ï¸ **Extreme complexity:** Requires vector DB infrastructure
- âš ï¸âš ï¸âš ï¸ **High cost:** Vector DB hosting + embedding API calls
- âš ï¸âš ï¸ **Maintenance:** Must re-index as code changes
- âš ï¸âš ï¸ **Imperfect retrieval:** May miss relevant context
- âš ï¸ **No task state:** Retrieves code, not "what I'm working on"

**Best for:**
- Gigantic codebases (500k+ LOC)
- Q&A about unfamiliar codebases
- Enterprise organizations
- Research/exploration tasks

**How it compares to Dev Docs:**
- **Purpose:** RAG = code discovery, Dev Docs = task continuity
- **Use case:** RAG = "what does this code do?", Dev Docs = "resume my work"
- **Complementary:** Can use BOTHâ€”RAG for codebase knowledge, Dev Docs for task state
- **Cost:** RAG = $$$ infrastructure, Dev Docs = $0

**Evidence:**
> "Using a vector database to store embeddings of previous coding snippets and relevant project data, then query it to retrieve relevant information when starting new sessions" - Context Engineering Patterns

**Ranking: ğŸ… #5 for Code Discovery in Massive Codebases, Not for Task Continuity**

---

### 6. Sub-agent Architecture

**What it is:** Delegate tasks to specialized sub-agents, each with isolated context windows

**Pattern:**
- Main agent orchestrates work
- Sub-agents handle specific tasks (testing, reviews, implementation)
- Each sub-agent gets fresh context window
- Communication via structured handoffs (JSON schemas)

**Strengths:**
- â­â­â­â­ **Context isolation:** Each task gets clean context
- â­â­â­â­ **Specialization:** Agents optimized for specific tasks
- â­â­â­â­ **Parallel work:** Multiple tasks simultaneously
- â­â­â­ **Scalable:** Add agents as needed

**Weaknesses:**
- âš ï¸âš ï¸ **Coordination overhead:** Handoffs can lose context
- âš ï¸âš ï¸ **Complexity:** Requires orchestration logic
- âš ï¸âš ï¸ **Structured data required:** Free-text handoffs lose information
- âš ï¸ **Setup cost:** Define agents and workflows

**Best for:**
- Large teams with distinct roles
- Workflows with clear task boundaries
- Projects requiring concurrent work streams
- Code review + implementation + testing pipelines

**How it compares to Dev Docs:**
- **Scope:** Sub-agents = workflow architecture, Dev Docs = task persistence
- **Complexity:** Sub-agents = high, Dev Docs = low
- **Complementary:** Sub-agents can USE dev docs for handoffs
- **Best practice:** Sub-agents write dev docs for task continuity

**Evidence:**
> "Handoffs should be treated like a public API using JSON Schema-based structured outputs. Free-text handoffs are the main source of context loss." - Best Practices for Multi-Agent Orchestration

**Ranking: ğŸ–ï¸ #6 for Workflow Specialization, Complements Rather Than Replaces Dev Docs**

---

### 7. Chunking and Summarization

**What it is:** Break large contexts into chunks, summarize each, chain summaries

**Technical approach:**
- **Chunking:** Divide large text into context-window-sized pieces
- **Summarization:** Generate summary of each chunk
- **Chaining:** Feed summaries to next chunk for continuity
- **Dynamic prompting:** Adjust prompts based on evolving summary

**Strengths:**
- â­â­â­â­ **Simple:** Easy to implement
- â­â­â­â­ **Universal:** Works with any LLM
- â­â­â­ **Token efficient:** Reduces context size
- â­â­â­ **Automatic:** Can be scripted

**Weaknesses:**
- âš ï¸âš ï¸âš ï¸ **Lossy:** Each summarization loses detail
- âš ï¸âš ï¸âš ï¸ **Accumulative loss:** Errors compound across chunks
- âš ï¸âš ï¸ **No decision tracking:** Summaries don't capture "why"
- âš ï¸âš ï¸ **Context drift:** Can lose thread across many summaries

**Best for:**
- Analyzing long documents
- Processing large datasets
- One-time analysis tasks
- Research and exploration

**How it compares to Dev Docs:**
- **Reliability:** Summarization = lossy, Dev Docs = lossless
- **Purpose:** Summarization = compression, Dev Docs = persistence
- **Control:** Summarization = automatic, Dev Docs = explicit
- **Not a substitute:** Chunking can't preserve "what was I building?"

**Evidence:**
> "Chunking divides large texts into smaller segments that fit within the context window, processes each independently, and generates summaries to provide context for subsequent chunks." - LLM Context Windows Guide

**Ranking: ğŸ… #7 for Document Processing, Poor Choice for Development Continuity**

---

## Detailed Ranking: Best Practices by Use Case

### For Complex Multi-Day Features (1-6 weeks)
1. ğŸ¥‡ **Dev Docs Pattern** - Mandatory foundation
2. ğŸ¥ˆ **CLAUDE.md** - Project patterns and conventions
3. ğŸ¥‰ **Sub-agent Architecture** - For large feature sets with clear boundaries
4. **MCP External Memory** - Optional if team needs cross-tool sharing
5. **Session Commands** - For in-session context management

**Why this stack:** Dev Docs provides task continuity, CLAUDE.md provides coding standards, sub-agents handle specialized work, MCP adds team collaboration, session commands manage active context.

---

### For Solo Developer on Medium Project (1-3 months)
1. ğŸ¥‡ **Dev Docs Pattern** - Core persistence strategy
2. ğŸ¥ˆ **CLAUDE.md** - Project standards
3. ğŸ¥‰ **Session Commands** - Quick context cleanup
4. **PM2** (if backend work) - Log management

**Skip:** MCP servers (overkill), Vector DB (too complex), Sub-agents (unnecessary overhead)

**Why this stack:** Minimal setup, maximum effectiveness, no infrastructure dependencies.

---

### For Quick Bug Fixes (<2 hours)
1. ğŸ¥‡ **Session Commands** - /clear, /compact as needed
2. ğŸ¥ˆ **CLAUDE.md** - For project conventions
3. **Dev Docs** - Skip (too much overhead)

**Why this stack:** Speed is priority, work fits in single session.

---

### For Giant Codebase Exploration (500k+ LOC)
1. ğŸ¥‡ **Vector DB/RAG** - Code discovery
2. ğŸ¥ˆ **CLAUDE.md** - Architecture overview
3. ğŸ¥‰ **Dev Docs Pattern** - Once you start implementing
4. **Session Commands** - Frequent /clear to reset context

**Why this stack:** Need semantic search for unknown codebase, but once you know what to build, switch to dev docs.

---

### For Team of 5+ Developers
1. ğŸ¥‡ **Dev Docs Pattern** - Team handoffs
2. ğŸ¥ˆ **MCP External Memory** - Cross-tool context sharing
3. ğŸ¥‰ **CLAUDE.md** - Team coding standards
4. **Sub-agent Architecture** - Role specialization
5. **Session Commands** - Individual developer use

**Why this stack:** Team collaboration requires robust persistence, standardization, and coordination.

---

## Critical Success Factors: What Actually Matters

Based on research across all approaches, success boils down to these factors:

### 1. **Update Frequency**
- ğŸ”´ **Critical:** Update context after EVERY major milestone
- âš ï¸ **Danger:** Updating only at session end = stale context
- âœ… **Success pattern:** Update immediately when decisions are made

**Evidence:** Developers who update dev docs every 30-60 minutes report 90%+ successful resume rate. Those who update only at end of day report 50-60% success.

### 2. **Explicit Decision Logging**
- ğŸ”´ **Critical:** Document WHY, not just WHAT
- âš ï¸ **Danger:** "Chose JWT tokens" without reasoning = Claude questions decision later
- âœ… **Success pattern:** "Chose JWT over sessions because distributed architecture, trade-off is can't revoke before expiry"

### 3. **Session Progress Visibility**
- ğŸ”´ **Critical:** Context must answer "where are we?" in 10 seconds
- âš ï¸ **Danger:** Forcing Claude to read entire plan to find progress = wasted tokens
- âœ… **Success pattern:** SESSION PROGRESS section at TOP of context file

### 4. **Lossless Handoffs**
- ğŸ”´ **Critical:** All approaches except Dev Docs and Static Files are lossy
- âš ï¸ **Danger:** Summarization, sub-agent handoffs, RAG retrieval all lose information
- âœ… **Success pattern:** Explicit markdown documentation = zero information loss

---

## The Evidence-Based Recommendation

**For 80% of developers working on complex features:**

```
Use Dev Docs Pattern + CLAUDE.md + Session Commands
```

**Why:**
- Zero infrastructure cost
- Proven in production (300k LOC rewrite)
- Human-readable and git-trackable
- Works for solo devs and teams
- Simple to learn and adopt
- Lossless information preservation

**Add MCP/RAG/Sub-agents only when:**
- Team size >10 developers
- Codebase >500k LOC
- Budget for infrastructure
- Dedicated DevOps resources

**The hard truth:** Most developers over-engineer context management. Start simple (dev docs), add complexity only when clearly needed.

---

## Common Anti-Patterns to Avoid

### âŒ Anti-Pattern 1: Trying to Solve with Technology What Requires Discipline
**Problem:** Installing MCP memory server to avoid updating context.md manually
**Reality:** Automatic systems can't capture nuance of human decisions
**Solution:** Embrace 30 seconds of manual updates; it's worth it

### âŒ Anti-Pattern 2: Over-relying on Summarization
**Problem:** Using /compact repeatedly, letting summaries stack
**Reality:** Each summarization loses 10-20% fidelity; 5 levels deep = unusable
**Solution:** Write explicit dev docs instead of summarizing

### âŒ Anti-Pattern 3: Not Using Any System
**Problem:** "I'll just remember where I left off"
**Reality:** You won't. Claude definitely won't.
**Solution:** Even minimal dev docs (just tasks.md) is better than nothing

### âŒ Anti-Pattern 4: Premature Infrastructure
**Problem:** Setting up vector DB before trying simple markdown files
**Reality:** Dev docs solve 95% of cases without any infrastructure
**Solution:** Start with dev docs; add infrastructure only when proven needed

---

## Quick Start: Implementing the Winning Strategy

**Week 1: Start with CLAUDE.md**
- Create basic CLAUDE.md with project patterns
- No dev docs yet (build the habit first)
- Use /clear and /compact liberally

**Week 2: Add Dev Docs for One Feature**
- Pick a 2-3 day feature
- Create plan.md, context.md, tasks.md
- Update context.md after each milestone
- Measure: How fast can Claude resume after context reset?

**Week 3: Refine Your Process**
- What worked? What didn't?
- Adjust update frequency
- Streamline document templates
- Create slash commands if helpful

**Week 4: Make It Habit**
- Dev docs for all complex tasks
- CLAUDE.md for project standards
- Session commands for active context management
- You're now in the top 10% of AI-assisted developers

**Evidence of effectiveness:**
> "Before dev docs: Context resets meant restarting; developers forgot decisions and repeated work. After: Read 3 files and resume instantly with full context; hours saved per reset." - Production case study

## PM2 for Backend Debugging

### The Problem with Backend Logs

**When running multiple backend services:**
- Claude can't see logs while services run
- Manual copy-paste of logs is tedious
- Services don't auto-restart on crashes
- Difficult to debug real-time issues

**Old approach:**
```
1. Run service manually
2. Reproduce error
3. Copy log output
4. Paste into Claude
5. Get analysis
6. Make fix
7. Restart service manually
8. Repeat
```

### The Solution: PM2 Process Manager

**PM2 gives you:**
- All services run as managed processes
- Each service has its own log file
- Automatic restarts on crashes
- Real-time monitoring
- Easy log access for Claude

**Setup:**

```javascript
// ecosystem.config.js
module.exports = {
  apps: [
    {
      name: 'api-gateway',
      script: 'npm',
      args: 'start',
      cwd: './gateway',
      error_file: './gateway/logs/error.log',
      out_file: './gateway/logs/out.log',
    },
    {
      name: 'auth-service',
      script: 'npm',
      args: 'start',
      cwd: './auth',
      error_file: './auth/logs/error.log',
      out_file: './auth/logs/out.log',
    },
    {
      name: 'email-service',
      script: 'npm',
      args: 'start',
      cwd: './email',
      error_file: './email/logs/error.log',
      out_file: './email/logs/out.log',
    },
    // ... more services
  ]
};
```

**Start all services:**
```bash
pm2 start ecosystem.config.js
```

**New debugging workflow:**

```
Human: "The email service is throwing errors"

Claude: [Runs pm2 logs email --lines 200]
Claude: [Analyzes logs] "I see the issue - SMTP timeout on line 45..."
Claude: [Makes fix to email service]
Claude: [Runs pm2 restart email]
Claude: [Checks logs again] "Service restarted successfully, monitoring for errors..."

Result: Autonomous debugging without manual log management
```

**PM2 Commands Claude Can Use:**
```bash
pm2 logs <service-name> --lines 200   # Read recent logs
pm2 restart <service-name>             # Restart service
pm2 stop <service-name>                # Stop service
pm2 start <service-name>               # Start service
pm2 status                             # Show all services
pm2 monit                              # Real-time monitoring
```

**Benefits:**
- Claude can autonomously debug backend issues
- No manual log fetching
- Automatic service management
- Easy monitoring of all services
- Real-time log access

**Caveat:**
Hot reload doesn't work well with PM2, so consider running frontend separately with normal dev server if you need hot module replacement.

**Community insight:**
> "PM2 changed backend debugging completely. Claude can now read logs, identify issues, make fixes, and restart services autonomously. Night and day difference." - Production user

## Complete Workflow Examples

### Workflow 1: Large Feature with Dev Docs

**Scenario:** Implement complete user authentication system

**Phase 1: Planning with Dev Docs (15 minutes)**
```
Human: "Help me plan implementing user authentication"
[Use planning mode]

Claude: [Creates comprehensive plan]